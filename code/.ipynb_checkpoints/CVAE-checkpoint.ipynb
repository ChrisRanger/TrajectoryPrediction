{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.remove('/opt/ros/kinetic/lib/python2.7/dist-packages')\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import l5kit\n",
    "from l5kit.data import LocalDataManager, ChunkedDataset\n",
    "from l5kit.dataset import AgentDataset, EgoDataset\n",
    "from l5kit.rasterization import build_rasterizer\n",
    "from torchvision.models.resnet import resnet50, resnet18, resnet34, resnet101\n",
    "from l5kit.evaluation import write_pred_csv, compute_metrics_csv, read_gt_csv, create_chopped_dataset\n",
    "from l5kit.evaluation.chop_dataset import MIN_FUTURE_STEPS\n",
    "from l5kit.evaluation.metrics import neg_multi_log_likelihood, time_displace\n",
    "from l5kit.geometry import transform_points\n",
    "from l5kit.visualization import PREDICTED_POINTS_COLOR, TARGET_POINTS_COLOR, draw_trajectory\n",
    "from prettytable import PrettyTable\n",
    "from pathlib import Path\n",
    "import cvae\n",
    "import utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm_notebook\n",
    "import gc, psutil\n",
    "\n",
    "print(l5kit.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'format_version': 4,\n",
    "    'data_path': '/home/chris/predict_code/Prediction/datasets/lyft-motion-prediction-autonomous-vehicles',\n",
    "    'model_params': {\n",
    "        'model_architecture': 'resnet34',\n",
    "        'history_num_frames': 10,\n",
    "        'history_step_size': 1,\n",
    "        'history_delta_time': 0.1,\n",
    "        'future_num_frames': 50,\n",
    "        'future_step_size': 1,\n",
    "        'future_delta_time': 0.1,\n",
    "        'model_name': \"CVAE_resnet34\",\n",
    "        'lr': 15e-4,\n",
    "        'weight_path': '',\n",
    "        'train': True,\n",
    "        'predict': False,\n",
    "    },\n",
    "    'raster_params': {\n",
    "        'raster_size': [400, 400],\n",
    "        'pixel_size': [0.3, 0.3],\n",
    "        'ego_center': [0.25, 0.5],\n",
    "        'map_type': 'py_semantic',\n",
    "        'satellite_map_key': 'aerial_map/aerial_map.png',\n",
    "        'semantic_map_key': 'semantic_map/semantic_map.pb',\n",
    "        'dataset_meta_key': 'meta.json',\n",
    "        'filter_agents_threshold': 0.5,\n",
    "    },\n",
    "    'train_data_loader': {\n",
    "        'key': 'scenes/train.zarr',\n",
    "        'batch_size': 12,\n",
    "        'shuffle': True,\n",
    "        'num_workers': 4,\n",
    "    },\n",
    "    'test_data_loader': {\n",
    "        'key': 'scenes/test.zarr',\n",
    "        'batch_size': 128,\n",
    "        'shuffle': False,\n",
    "        'num_workers': 4,\n",
    "    },\n",
    "    'train_params': {\n",
    "        'multi': 'best',\n",
    "        'steps': 200000,\n",
    "        'update_steps': 1000,\n",
    "        'metrics_steps': 1000,\n",
    "        'checkpoint_steps': 1000,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "| Num Scenes | Num Frames | Num Agents | Num TR lights | Total Time (hr) | Avg Frames per Scene | Avg Agents per Frame | Avg Scene Time (sec) | Avg Frame frequency |\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "|   16265    |  4039527   | 320124624  |    38735988   |      112.19     |        248.36        |        79.25         |        24.83         |        10.00        |\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+ 22496709\n"
     ]
    }
   ],
   "source": [
    "# 加载数据集，准备device\n",
    "DIR_INPUT = cfg[\"data_path\"]\n",
    "os.environ[\"L5KIT_DATA_FOLDER\"] = DIR_INPUT\n",
    "dm = LocalDataManager()\n",
    "rasterizer = build_rasterizer(cfg, dm)\n",
    "train_cfg = cfg[\"train_data_loader\"]\n",
    "train_zarr = ChunkedDataset(dm.require(train_cfg[\"key\"])).open(cached=False)  # to prevent run out of memory\n",
    "train_dataset = AgentDataset(cfg, train_zarr, rasterizer)\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=train_cfg[\"shuffle\"],\n",
    "                              batch_size=train_cfg[\"batch_size\"], num_workers=train_cfg[\"num_workers\"])\n",
    "print(train_dataset, len(train_dataset))\n",
    "\n",
    "train_writer = SummaryWriter('../log/CVAE', comment='CVAE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 主训练\n",
    "def forward(data, model, device, criterion=cvae.loss_cvae, compute_loss=True):\n",
    "    image = data[\"image\"].to(device)\n",
    "    history_traj = data[\"history_positions\"].flip(1)\n",
    "    history_yaw = data[\"history_yaws\"].flip(1)\n",
    "    history_availabilities = torch.unsqueeze(data[\"history_availabilities\"].flip(1), 2)\n",
    "    history = torch.cat([history_traj, history_yaw], 2)\n",
    "    history = torch.cat([history, history_availabilities], 2).to(device)\n",
    "    # print(history_traj.shape, history_yaw.shape, history_availabilities.shape)\n",
    "    history = torch.cat([history_traj, history_yaw], 2)\n",
    "    history = torch.cat([history, history_availabilities], 2).to(device)\n",
    "    \n",
    "    target_availabilities = data[\"target_availabilities\"].to(device)\n",
    "    targets = data[\"target_positions\"].to(device)\n",
    "    # history_traj: bz * seq_len *\n",
    "    # print(image.shape, history.shape)\n",
    "    preds, confidences, _, z_mean, z_var = model(image, history.permute(1, 0, 2))\n",
    "    # skip compute loss if we are doing prediction\n",
    "    loss, loss_pred = criterion(targets, preds, confidences, target_availabilities, z_mean, z_var) if compute_loss else 0\n",
    "    return loss, loss_pred, preds, confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda:0\n"
     ]
    }
   ],
   "source": [
    "# 建立模型\n",
    "model = cvae.CVAE(cfg, traj_dim=256, cont_dim=256, latent_dim=128, mode_dim=3, v_dim=4)\n",
    "weight_path = cfg[\"model_params\"][\"weight_path\"]\n",
    "if weight_path:\n",
    "    model.load_state_dict(torch.load(weight_path))\n",
    "    print(weight_path, 'loaded')\n",
    "#print(model)\n",
    "model.cuda()\n",
    "learning_rate = cfg[\"model_params\"][\"lr\"]\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer,step_size=1000,gamma = 0.96)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'device {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b1bc3567eb04e3cbacf84adbbc9eb65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train, mode is  best\n",
      "i:  1000 loss(avg):  659.22594 loss_pre(avg):  577.54444 loss_ade(avg):    2.19191 loss_fde(avg):    2.69602 lr(curr): 0.001440  13.46mins | \n",
      "i:  2000 loss(avg):  506.37984 loss_pre(avg):  434.89064 loss_ade(avg):    2.41963 loss_fde(avg):    3.21023 lr(curr): 0.001382  26.96mins | \n",
      "i:  3000 loss(avg):  372.80107 loss_pre(avg):  329.87699 loss_ade(avg):    4.02538 loss_fde(avg):    3.70658 lr(curr): 0.001327  40.72mins | \n",
      "i:  4000 loss(avg):  428.68438 loss_pre(avg):  369.44881 loss_ade(avg):    2.38924 loss_fde(avg):    1.90009 lr(curr): 0.001274  54.18mins | \n",
      "i:  5000 loss(avg):  335.12291 loss_pre(avg):  301.64193 loss_ade(avg):    2.25406 loss_fde(avg):    1.92022 lr(curr): 0.001223  67.56mins | \n",
      "i:  6000 loss(avg):  305.65146 loss_pre(avg):  261.20327 loss_ade(avg):    2.14860 loss_fde(avg):    4.40910 lr(curr): 0.001174  81.16mins | \n",
      "i:  7000 loss(avg):  305.49311 loss_pre(avg):  271.65749 loss_ade(avg):    1.85033 loss_fde(avg):    2.82479 lr(curr): 0.001127  94.41mins | \n",
      "i:  8000 loss(avg):  268.39269 loss_pre(avg):  240.41245 loss_ade(avg):    0.39515 loss_fde(avg):    0.64451 lr(curr): 0.001082  107.75mins | \n",
      "i:  9000 loss(avg):  255.96642 loss_pre(avg):  226.38106 loss_ade(avg):    0.26635 loss_fde(avg):    0.31989 lr(curr): 0.001039  121.16mins | \n",
      "i: 10000 loss(avg):  275.72310 loss_pre(avg):  249.29104 loss_ade(avg):    1.64318 loss_fde(avg):    2.04368 lr(curr): 0.000997  134.56mins | \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-68a05b8c188d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mloss_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lyft/lib/python3.7/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lyft/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lyft/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    105\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "if cfg[\"model_params\"][\"train\"]:\n",
    "    tr_it = iter(train_dataloader)\n",
    "    n_steps = cfg[\"train_params\"][\"steps\"]\n",
    "    progress_bar = tqdm_notebook(range(1, 1 + n_steps), mininterval=5.)\n",
    "    iterations = []\n",
    "    losses = []\n",
    "    losses_pre = []\n",
    "    losses_ade = []\n",
    "    losses_fde = []\n",
    "    metrics = []\n",
    "    metrics_pre = []\n",
    "    metrics_ade = []\n",
    "    metrics_fde = []\n",
    "    times = []\n",
    "    model_name = cfg[\"model_params\"][\"model_name\"]\n",
    "    multi_mode = cfg[\"train_params\"][\"multi\"]\n",
    "    update_steps = cfg['train_params']['update_steps']\n",
    "    metrics_steps = cfg['train_params']['metrics_steps']\n",
    "    checkpoint_steps = cfg['train_params']['checkpoint_steps']\n",
    "    t_start = time.time()\n",
    "    torch.set_grad_enabled(True)\n",
    "    print('start train, mode is ', multi_mode)\n",
    "\n",
    "    for i in progress_bar:\n",
    "        try:\n",
    "            data = next(tr_it)\n",
    "        except StopIteration:\n",
    "            tr_it = iter(train_dataloader)\n",
    "            data = next(tr_it)\n",
    "        model.train()  # somehow we need this is ever batch or it perform very bad (not sure why)\n",
    "        loss, loss_pre, pred, conf = forward(data, model, device)\n",
    "\n",
    "        # Backward pass\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_v = loss.item()\n",
    "        loss_pre_v = loss_pre.item()\n",
    "        losses.append(loss_v)\n",
    "        losses_pre.append(loss_pre_v)\n",
    "        train_writer.add_scalar('loss', loss_v, i)\n",
    "        train_writer.add_scalar('loss_pre', loss_pre_v, i)\n",
    "        \n",
    "        if i % metrics_steps == 0:\n",
    "            # 求其他尺度指标\n",
    "            loss_ade = utils._average_displacement_error(data[\"target_positions\"].to(device), \n",
    "                                                       pred, conf, data[\"target_availabilities\"].to(device),\n",
    "                                                       mode=multi_mode)\n",
    "            loss_fde = utils._final_displacement_error(data[\"target_positions\"].to(device), \n",
    "                                                       pred, conf, data[\"target_availabilities\"].to(device),\n",
    "                                                       mode=multi_mode)\n",
    "            losses_ade.append(loss_ade.item())\n",
    "            losses_fde.append(loss_fde.item())\n",
    "            train_writer.add_scalar('loss_ade', loss_ade, i)\n",
    "            train_writer.add_scalar('loss_fde', loss_fde, i)\n",
    "\n",
    "        if i % update_steps == 0:\n",
    "            mean_losses = np.mean(losses)\n",
    "            mean_losses_pre = np.mean(losses_pre)\n",
    "            losses = []\n",
    "            losses_pre = []\n",
    "            train_writer.add_scalar('mean_loss', mean_losses, i)\n",
    "            train_writer.add_scalar('mean_loss_pre', mean_losses_pre, i)\n",
    "            mean_losses_ade = np.mean(losses_ade)\n",
    "            mean_losses_fde = np.mean(losses_fde)\n",
    "            losses_ade = []\n",
    "            losses_fde = []\n",
    "            train_writer.add_scalar('loss_ade', mean_losses_ade, i)\n",
    "            train_writer.add_scalar('loss_fde', mean_losses_fde, i)\n",
    "            timespent = (time.time() - t_start) / 60\n",
    "            lr = optimizer.param_groups[0]['lr']\n",
    "            train_writer.add_scalar('lr', lr, i)\n",
    "            print('i: %5d' % i,\n",
    "                  'loss(avg): %10.5f' % mean_losses,'loss_pre(avg): %10.5f' % mean_losses_pre, \n",
    "                  'loss_ade(avg): %10.5f' % mean_losses_ade,'loss_fde(avg): %10.5f' % mean_losses_fde,\n",
    "                  'lr(curr): %f' % lr, ' %.2fmins' % timespent, end=' | \\n')\n",
    "            if i % checkpoint_steps == 0:\n",
    "                torch.save(model.state_dict(), f'../model/{model_name}.pth')\n",
    "                torch.save(model, f'../model/{model_name}.pkl')\n",
    "                torch.save(optimizer.state_dict(), f'../model/{model_name}_optimizer.pth')\n",
    "            iterations.append(i)\n",
    "            metrics.append(mean_losses)\n",
    "            metrics_pre.append(mean_losses_pre)\n",
    "            metrics_ade.append(mean_losses_ade)\n",
    "            metrics_fde.append(mean_losses_fde)\n",
    "            times.append(timespent)\n",
    "\n",
    "    torch.save(model.state_dict(), f'../model/{model_name}_final.pth')\n",
    "    torch.save(model, f'../model/{model_name}_final.pkl')\n",
    "    torch.save(optimizer.state_dict(), f'../model/{model_name}_optimizer_final.pth')\n",
    "    results = pd.DataFrame({\n",
    "        'iterations': iterations,\n",
    "        'metrics (avg)': metrics,\n",
    "        'metrics_pre (avg)': metrics_pre,\n",
    "        'metrics_ade (avg)': metrics_ade,\n",
    "        'metrics_fde (avg)': metrics_fde,\n",
    "        'elapsed_time (mins)': times,\n",
    "    })\n",
    "    results.to_csv(f'train_metrics_{model_name}_{n_steps}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
