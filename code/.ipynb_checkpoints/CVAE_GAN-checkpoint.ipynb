{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Tuple, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import l5kit\n",
    "from l5kit.data import LocalDataManager, ChunkedDataset\n",
    "from l5kit.dataset import AgentDataset, EgoDataset\n",
    "from l5kit.rasterization import build_rasterizer\n",
    "from torchvision.models.resnet import resnet50, resnet18, resnet34, resnet101\n",
    "from l5kit.evaluation import write_pred_csv, compute_metrics_csv, read_gt_csv, create_chopped_dataset\n",
    "from l5kit.evaluation.chop_dataset import MIN_FUTURE_STEPS\n",
    "from l5kit.evaluation.metrics import neg_multi_log_likelihood, time_displace\n",
    "from l5kit.geometry import transform_points\n",
    "from l5kit.visualization import PREDICTED_POINTS_COLOR, TARGET_POINTS_COLOR, draw_trajectory\n",
    "from prettytable import PrettyTable\n",
    "from pathlib import Path\n",
    "import utils\n",
    "import cgan\n",
    "import cvae\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm_notebook\n",
    "import gc, psutil\n",
    "\n",
    "print(l5kit.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'format_version': 4,\n",
    "    'data_path': '/home/yx/WSY/Prediction/datasets/lyft-motion-prediction-autonomous-vehicles',\n",
    "    'model_params': {\n",
    "        'model_architecture': 'resnet34',\n",
    "        'history_num_frames': 10,\n",
    "        'history_step_size': 1,\n",
    "        'history_delta_time': 0.1,\n",
    "        'future_num_frames': 50,\n",
    "        'future_step_size': 1,\n",
    "        'future_delta_time': 0.1,\n",
    "        'model_name_g': \"CVAEGAN_resnet34_G\",\n",
    "        'model_name_d': \"CVAEGAN_resnet34_D\",\n",
    "        'lr_g': 1e-3,\n",
    "        'lr_d': 1e-3,\n",
    "        'weight_path_g': '',\n",
    "        'weight_path_d': '',\n",
    "        'train': True,\n",
    "        'predict': False,\n",
    "    },\n",
    "    'raster_params': {\n",
    "        'raster_size': [224, 224],\n",
    "        'pixel_size': [0.5, 0.5],\n",
    "        'ego_center': [0.25, 0.5],\n",
    "        'map_type': 'py_semantic',\n",
    "        'satellite_map_key': 'aerial_map/aerial_map.png',\n",
    "        'semantic_map_key': 'semantic_map/semantic_map.pb',\n",
    "        'dataset_meta_key': 'meta.json',\n",
    "        'filter_agents_threshold': 0.5,\n",
    "    },\n",
    "    'train_data_loader': {\n",
    "        'key': 'scenes/train.zarr',\n",
    "        'batch_size': 16,\n",
    "        'shuffle': True,\n",
    "        'num_workers': 4,\n",
    "    },\n",
    "    'test_data_loader': {\n",
    "        'key': 'scenes/test.zarr',\n",
    "        'batch_size': 128,\n",
    "        'shuffle': False,\n",
    "        'num_workers': 4,\n",
    "    },\n",
    "    'train_params': {\n",
    "        'multi': 'best',\n",
    "        'steps': 400000,\n",
    "        'update_steps': 1000,\n",
    "        'metrics_steps': 100,\n",
    "        'checkpoint_steps': 2000,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "| Num Scenes | Num Frames | Num Agents | Num TR lights | Total Time (hr) | Avg Frames per Scene | Avg Agents per Frame | Avg Scene Time (sec) | Avg Frame frequency |\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "|   16265    |  4039527   | 320124624  |    38735988   |      112.19     |        248.36        |        79.25         |        24.83         |        10.00        |\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+ 22496709\n"
     ]
    }
   ],
   "source": [
    "# 加载数据集，准备device\n",
    "DIR_INPUT = cfg[\"data_path\"]\n",
    "os.environ[\"L5KIT_DATA_FOLDER\"] = DIR_INPUT\n",
    "dm = LocalDataManager()\n",
    "rasterizer = build_rasterizer(cfg, dm)\n",
    "train_cfg = cfg[\"train_data_loader\"]\n",
    "train_zarr = ChunkedDataset(dm.require(train_cfg[\"key\"])).open(cached=False)  # to prevent run out of memory\n",
    "train_dataset = AgentDataset(cfg, train_zarr, rasterizer)\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=train_cfg[\"shuffle\"],\n",
    "                              batch_size=train_cfg[\"batch_size\"], num_workers=train_cfg[\"num_workers\"])\n",
    "print(train_dataset, len(train_dataset))\n",
    "\n",
    "train_writer = SummaryWriter('../log/CVAEGAN', comment='CVAEGAN')\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda:0\n"
     ]
    }
   ],
   "source": [
    "# 建立模型\n",
    "generator = cvae.CVAE(cfg, traj_dim=256, cont_dim=256, mode_dim=3, v_dim=4)\n",
    "discriminator = cgan.discriminator(cfg, h_dim=256, cont_dim=256)\n",
    "weight_path_g = cfg[\"model_params\"][\"weight_path_g\"]\n",
    "if weight_path_g:\n",
    "    generator.load_state_dict(torch.load(weight_path))\n",
    "weight_path_d = cfg[\"model_params\"][\"weight_path_d\"]\n",
    "if weight_path_d:\n",
    "    discriminator.load_state_dict(torch.load(weight_path))\n",
    "generator.cuda()\n",
    "discriminator.cuda()\n",
    "g_loss_fn = utils.g_loss\n",
    "d_loss_fn = utils.d_loss\n",
    "\n",
    "learning_rate_g = cfg[\"model_params\"][\"lr_g\"]\n",
    "learning_rate_d = cfg[\"model_params\"][\"lr_d\"]\n",
    "optimizer_g = optim.Adam(generator.parameters(), lr=learning_rate_g)\n",
    "optimizer_d = optim.Adam(discriminator.parameters(), lr=learning_rate_d)\n",
    "\n",
    "scheduler_g = optim.lr_scheduler.StepLR(optimizer_g,step_size=1000,gamma = 0.96)\n",
    "scheduler_d = optim.lr_scheduler.StepLR(optimizer_d,step_size=1000,gamma = 0.96)\n",
    "print(f'device {device}')\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成器训练\n",
    "def forward_g(data, model_g, model_d, device, optimizer, scheduler, criterion=utils.g_loss):\n",
    "    image = data[\"image\"].to(device)\n",
    "    history_traj = data[\"history_positions\"].flip(1)\n",
    "    history_yaw = data[\"history_yaws\"].flip(1)\n",
    "    history_availabilities = torch.unsqueeze(data[\"history_availabilities\"].flip(1), 2)\n",
    "    history = torch.cat([history_traj, history_yaw], 2)\n",
    "    history = torch.cat([history, history_availabilities], 2).to(device)\n",
    "    target_availabilities = data[\"target_availabilities\"].to(device)\n",
    "    targets = data[\"target_positions\"].to(device)\n",
    "    \n",
    "    model_g.train()\n",
    "    preds, confidences, condition, z_mean, z_var = model_g(image, history.permute(1, 0, 2))\n",
    "    traj_fake = multi2single(preds, targets, target_availabilities, confidences, mode='best')\n",
    "    score_fake = model_d(traj_fake.permute(1, 0, 2), condition)\n",
    "    # 判别loss + nll_loss\n",
    "    loss = criterion(score_fake) + cvae.loss_cvae(targets, preds, confidences, \n",
    "                                                  target_availabilities, z_mean, z_var)[0]\n",
    "    scheduler.step()        \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss, preds, confidences\n",
    "\n",
    "# 判别器训练\n",
    "def forward_d(data, model_g, model_d, device, optimizer, scheduler, criterion=utils.d_loss):\n",
    "    image = data[\"image\"].to(device)\n",
    "    history_traj = data[\"history_positions\"].flip(1)\n",
    "    history_yaw = data[\"history_yaws\"].flip(1)\n",
    "    history_availabilities = torch.unsqueeze(data[\"history_availabilities\"].flip(1), 2)\n",
    "    history = torch.cat([history_traj, history_yaw], 2)\n",
    "    history = torch.cat([history, history_availabilities], 2).to(device)\n",
    "    target_availabilities = data[\"target_availabilities\"].to(device)\n",
    "    targets = data[\"target_positions\"].to(device)\n",
    "    \n",
    "    model_d.train()\n",
    "    preds, confidences, condition, _, _ = model_g(image, history.permute(1, 0, 2))\n",
    "    traj_fake = multi2single(preds, targets, target_availabilities, confidences, mode='best')\n",
    "    score_fake = model_d(traj_fake.permute(1, 0, 2), condition)\n",
    "    score_real = model_d(targets.permute(1, 0, 2), condition)\n",
    "    loss = criterion(score_real, score_fake)\n",
    "    scheduler.step()        \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "# 多模态轨迹挑选函数，支持多种模态捕捉方式\n",
    "def multi2single(traj_multi, ground_truth, avails, confidence, mode='best'):\n",
    "    # 三种模式： best最接近gt那条; mean求期望; most取概率最大那条，其他方式待补充\n",
    "    if mode == 'most':\n",
    "        index = confidence.argmax(dim=1)\n",
    "        selected_traj = gt\n",
    "        for i in range(0, ground_truth.shape[0]):\n",
    "            selected_traj[i] = traj_multi[i][index[i]]\n",
    "        selected_traj = selected_traj.squeeze(1)\n",
    "        return selected_traj\n",
    "    elif mode == 'mean':\n",
    "        traj_multi[:][0] = traj_multi[:][0] * confidence[0]\n",
    "        traj_multi[:][1] = traj_multi[:][1] * confidence[0]\n",
    "        traj_multi[:][2] = traj_multi[:][2] * confidence[0]\n",
    "        traj_multi = torch.sum(traj_multi, dim=1)\n",
    "        return traj_multi/3.0\n",
    "    elif mode == 'best':\n",
    "        gt = torch.unsqueeze(ground_truth, 1)  # add modes\n",
    "        avails = avails[:, None, :, None]  # add modes and cords\n",
    "        # 求L2距离平方\n",
    "        error = torch.sum(((gt - traj_multi) * avails) ** 2, dim=3)\n",
    "        # 时序轴上求平均\n",
    "        error = torch.mean(error, dim=2)\n",
    "        # 模态轴上求最小值\n",
    "        index = error.argmin(dim=1)\n",
    "        selected_traj = gt\n",
    "        for i in range(0, ground_truth.shape[0]):\n",
    "            selected_traj[i] = traj_multi[i][index[i]]\n",
    "        selected_traj = selected_traj.squeeze(1)\n",
    "        return selected_traj\n",
    "    else:\n",
    "        print('error, non-exist mode for select traj from multi!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daaba10307cc480991ac0f73a464296a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=400000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train, mode is  best\n",
      "i:  1000 loss_g(avg):    1.26360 loss_nll(avg): 4585.45356 loss_d(avg):    1.50219 loss_ade(avg):    5.67796 loss_fde(avg):    7.50951 lr(g): 0.000922 lr(d): 0.001000  6.32mins | \n"
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "if cfg[\"model_params\"][\"train\"]:\n",
    "    tr_it = iter(train_dataloader)\n",
    "    n_steps = cfg[\"train_params\"][\"steps\"]\n",
    "    progress_bar = tqdm_notebook(range(1, 1 + n_steps), mininterval=5.)\n",
    "    losses_g = []\n",
    "    losses_d = []\n",
    "    losses_nll = []\n",
    "    losses_ade = []\n",
    "    losses_fde = []\n",
    "    iterations = []\n",
    "    metrics_g = []\n",
    "    metrics_d = []\n",
    "    metrics_nll = []\n",
    "    metrics_ade = []\n",
    "    metrics_fde = []\n",
    "    times = []\n",
    "    model_name_g = cfg[\"model_params\"][\"model_name_g\"]\n",
    "    model_name_d = cfg[\"model_params\"][\"model_name_d\"]\n",
    "    multi_mode = cfg[\"train_params\"][\"multi\"]\n",
    "    update_steps = cfg['train_params']['update_steps']\n",
    "    metrics_steps = cfg['train_params']['metrics_steps']\n",
    "    checkpoint_steps = cfg['train_params']['checkpoint_steps']\n",
    "    t_start = time.time()\n",
    "    torch.set_grad_enabled(True)\n",
    "    print('start train, mode is ', multi_mode)\n",
    "    \n",
    "    \n",
    "\n",
    "    for i in progress_bar:\n",
    "        try:\n",
    "            data = next(tr_it)\n",
    "        except StopIteration:\n",
    "            tr_it = iter(train_dataloader)\n",
    "            data = next(tr_it)\n",
    "        \n",
    "        # 判别器训练\n",
    "        loss_d = forward_d(data, generator, discriminator, device,\n",
    "                           optimizer_g, scheduler_g, criterion=d_loss_fn)\n",
    "        loss_d = loss_d.item()\n",
    "        losses_d.append(loss_d)\n",
    "        train_writer.add_scalar('loss_d', losses_d[0], i)\n",
    "        \n",
    "        # 生成器训练\n",
    "        loss_g, preds, confidences = forward_g(data, generator, discriminator,\n",
    "                                               device, optimizer_g, scheduler_g,\n",
    "                                               criterion=g_loss_fn)\n",
    "        loss_g = loss_g.item()\n",
    "        losses_g.append(loss_g)\n",
    "        train_writer.add_scalar('loss_g', losses_g[0], i)\n",
    "        \n",
    "        if i % metrics_steps == 0:\n",
    "            # 求其他尺度指标\n",
    "            loss_ade = utils._average_displacement_error(data[\"target_positions\"].to(device), \n",
    "                                                         preds, confidences,\n",
    "                                                         data[\"target_availabilities\"].to(device), \n",
    "                                                         mode=multi_mode)\n",
    "            loss_fde = utils._final_displacement_error(data[\"target_positions\"].to(device), \n",
    "                                                       preds, confidences,\n",
    "                                                       data[\"target_availabilities\"].to(device),\n",
    "                                                       mode=multi_mode)\n",
    "            loss_nll = utils.pytorch_neg_multi_log_likelihood_batch(data[\"target_positions\"].to(device),\n",
    "                                                                    preds, confidences, \n",
    "                                                                    data[\"target_availabilities\"].to(device))\n",
    "            losses_ade.append(loss_ade.item())\n",
    "            losses_fde.append(loss_fde.item())\n",
    "            losses_nll.append(loss_nll.item())\n",
    "            train_writer.add_scalar('loss_nll', loss_nll, i)\n",
    "            train_writer.add_scalar('loss_ade', loss_ade, i)\n",
    "            train_writer.add_scalar('loss_fde', loss_fde, i)\n",
    "\n",
    "        if i % update_steps == 0:\n",
    "            mean_losses_g = np.mean(loss_g)\n",
    "            mean_losses_d = np.mean(loss_d)\n",
    "            train_writer.add_scalar('mean_loss_g', mean_losses_g, i)\n",
    "            train_writer.add_scalar('mean_loss_d', mean_losses_d, i)\n",
    "            mean_losses_ade = np.mean(losses_ade)\n",
    "            mean_losses_fde = np.mean(losses_fde)\n",
    "            mean_losses_nll = np.mean(losses_nll)\n",
    "            losses_g = []\n",
    "            losses_d = []\n",
    "            losses_nll = []\n",
    "            losses_ade = []\n",
    "            losses_fde = []\n",
    "            train_writer.add_scalar('loss_nll', mean_losses_nll, i)\n",
    "            train_writer.add_scalar('loss_ade', mean_losses_ade, i)\n",
    "            train_writer.add_scalar('loss_fde', mean_losses_fde, i)\n",
    "            timespent = (time.time() - t_start) / 60\n",
    "            curr_lr_g = optimizer_g.param_groups[0]['lr']\n",
    "            curr_lr_d = optimizer_d.param_groups[0]['lr']\n",
    "            print('i: %5d' % i,\n",
    "                  'loss_g(avg): %10.5f' % mean_losses_g, 'loss_nll(avg): %10.5f' % mean_losses_nll,\n",
    "                  'loss_d(avg): %10.5f' % mean_losses_d, 'loss_ade(avg): %10.5f' % mean_losses_ade,\n",
    "                  'loss_fde(avg): %10.5f' % mean_losses_fde,'lr(g): %f' %curr_lr_g, 'lr(d): %f' %curr_lr_d,\n",
    "                  ' %.2fmins' % timespent, end=' | \\n')\n",
    "            if i % checkpoint_steps == 0:\n",
    "                torch.save(generator, f'../model/{model_name_g}.pkl')\n",
    "                torch.save(generator.state_dict(), f'../model/{model_name_g}.pth')\n",
    "                torch.save(optimizer_g.state_dict(), f'../model/{model_name_g}_optimizer.pth')\n",
    "                torch.save(discriminator, f'../model/{model_name_d}.pkl')\n",
    "                torch.save(discriminator.state_dict(), f'../model/{model_name_d}.pth')\n",
    "                torch.save(optimizer_d.state_dict(), f'../model/{model_name_d}_optimizer.pth')\n",
    "            iterations.append(i)\n",
    "            metrics_g.append(mean_losses_g)\n",
    "            metrics_d.append(mean_losses_d)\n",
    "            metrics_ade.append(mean_losses_ade)\n",
    "            metrics_fde.append(mean_losses_fde)\n",
    "            metrics_nll.append(mean_losses_nll)\n",
    "            times.append(timespent)\n",
    "\n",
    "    torch.save(generator.state_dict(), f'../model/{model_name_g}_final.pth')\n",
    "    torch.save(generator, f'../model/{model_name_g}_final.pkl')\n",
    "    torch.save(optimizer_g.state_dict(), f'../model/{model_name_g}_optimizer_final.pth')\n",
    "    torch.save(discriminator, f'../model/{model_name_d}.pkl')\n",
    "    torch.save(discriminator.state_dict(), f'../model/{model_name_d}.pth')\n",
    "    torch.save(optimizer_d.state_dict(), f'../model/{model_name_d}_optimizer.pth')\n",
    "    results = pd.DataFrame({\n",
    "        'iterations': iterations,\n",
    "        'metrics_g (avg)': metrics_g,\n",
    "        'metrics_d (avg)': metrics_d,\n",
    "        'metrics_ade (avg)': metrics_ade,\n",
    "        'metrics_fde (avg)': metrics_fde,\n",
    "        'metrics_nll (avg)': metrics_nll,\n",
    "        'elapsed_time (mins)': times,\n",
    "    })\n",
    "    results.to_csv(f'../log/train_metrics_cgan_{n_steps}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
